{"cells":[{"cell_type":"markdown","metadata":{"id":"qHVAS80lc4O8"},"source":["#**EXP 1**"]},{"cell_type":"markdown","source":[],"metadata":{"id":"vNB4gehYKvq4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItbWMM2wBJw3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712473143355,"user_tz":420,"elapsed":1519,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"27dbba5e-e86e-4648-d388-0382212f03bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MJIXwOgfiT5"},"outputs":[],"source":["!pip install transformers datasets peft accelerate bitsandbytes trl safetensors torch --no-cache"]},{"cell_type":"code","source":["import pandas as pd\n","import json\n","from datasets import load_dataset\n","\n","# Define your base path and file locations\n","base_path = '/content/drive/My Drive/Colab Notebooks/CSCI 564 NLP'\n","csv_path = f'{base_path}/hindi_data/romanized_hindi_english_paper.csv'\n","json_path = f'{base_path}/hindi_data/romanized_hindi_english_paper_formatted.json'"],"metadata":{"id":"-c0DlPFWZfcr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assuming df is your pandas DataFrame\n","column_names = ['H', 'RH', 'E']\n","df = pd.read_csv(csv_path, names=column_names, header=0, nrows=8000)\n","df['RH'] = df['RH'].astype(str)\n","df['E'] = df['E'].astype(str)\n","df = df.dropna()\n","# Convert DataFrame rows to desired format, focusing on 'RH' (Romanized Hindi) and 'E' (English)\n","formatted_list = df.apply(lambda row: {'hindi': row['RH'], 'english': row['E']}, axis=1).tolist()\n","\n","# Save the formatted list as a JSON file\n","with open(json_path, 'w') as f:\n","    json.dump(formatted_list, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["05755a531ebd4bf992711adc750d975e","a53e873b2b05404f959153fba082147a","7bb4c80823fe4ab285f29674f0cd5e3b","752f8bbe0eab45f0a86efa1ded41ed10","8bd8e370cacd4297900e0f159159495a","4f25a63b6258496ea104c605fdd28aeb","c498d0c9139d4d2fa14dd577e1e9566d","0c835da94c984ffa9676d3d038092a1e","308962cecd0b4e64b4a81aa7a16de987","0b525f2807234cc292c4034837872e48","7b31daa140484ba2a453c6d6091f3ec4"]},"id":"CdJKslk9krGR","executionInfo":{"status":"ok","timestamp":1712470836244,"user_tz":420,"elapsed":1226,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"5da80a17-f594-4671-d2bb-e0f6e1d37e23"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05755a531ebd4bf992711adc750d975e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training dataset sample: {'english': 'king of diamonds', 'hindi': 'int kaa badshah'}\n","Evaluation dataset sample: {'english': '_ Fullscreen', 'hindi': 'fullscreen (_ f)'}\n"]}]},{"cell_type":"code","source":["# Load the dataset from the JSON file\n","dataset = load_dataset(\"json\", data_files=json_path, split=\"train\")\n","\n","# Split the dataset into training and evaluation datasets with an 80/20 split\n","train_dataset = dataset.train_test_split(test_size=0.2)[\"train\"]\n","eval_dataset = dataset.train_test_split(test_size=0.2)[\"test\"]\n","\n","# The train_dataset and eval_dataset are now available for use\n","print(\"Training dataset sample:\", train_dataset[0])\n","print(\"Evaluation dataset sample:\", eval_dataset[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iAni8HBoZLl4","executionInfo":{"status":"ok","timestamp":1712473905749,"user_tz":420,"elapsed":1021,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"09e958c1-f82d-4fca-a602-7153db69001e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training dataset sample: {'english': 'Save message', 'hindi': 'yeah sandesh bhejen'}\n","Evaluation dataset sample: {'english': 'This game does not have hint support yet.', 'hindi': 'iss khel main abb taka koi sanket samarthan upalabdh nahin hai.'}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9_75qHF9x0S"},"outputs":[],"source":["from accelerate import FullyShardedDataParallelPlugin, Accelerator\n","from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n","\n","fsdp_plugin = FullyShardedDataParallelPlugin(\n","    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n","    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",")\n","\n","accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"]},{"cell_type":"code","source":["def formatting_func(example):\n","    text = f\"### Romanized Hindi: {example['hindi']}\\n ### English: {example['english']}\"\n","    return text"],"metadata":{"id":"S9w4i7joqPME"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mistral-7B-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")"],"metadata":{"id":"kCpUYMIuqWVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"],"metadata":{"id":"PC7fRMkbX_7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD2lMuBQUQZY"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    padding_side=\"left\",\n","    add_eos_token=True,\n","    add_bos_token=True,\n",")\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","def generate_and_tokenize_prompt(prompt):\n","    return tokenizer(formatting_func(prompt))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSuelQtEy0qR","executionInfo":{"status":"ok","timestamp":1712470923100,"user_tz":420,"elapsed":2480,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["48090858c0f74d479bf4a05b162415da","fac0b02292284cbba2c7ee17e41c6d35","1eb3feb1713549af83b9a079a1c4e56f","82ca17377d6745e29bab9b8926ec278e","2428ff9f56154c1d8d7077a8eb6d3713","36a5c7b4236a4969bbc4ce1d8be5f6ee","2088af3dc5d9450c9e6f2e6df178e7f0","e3db84c5d1904ea0a41b1e48bc6b2306","e2d3a41285d64ee5ab3df211ee2547c0","646898f367fc460d80ab3b7b28cd5c30","bba3ca044f2448179e7105d36e225af2","c4b3d5462d4947a5a292d72f2dd3f970","acce87a4dbcb4fcb94f0efa288586c58","65ed925623434a6caea597864fc141df","106e3a869c2a47d4957787d84434046e","51f8fbc893604fc893c10d696dbae8e2","32df641bd8034ef5a4ac5a9fa0923e78","59d12f4991424b6b9875d55b5542f2c9","59a7f8e2b1a347ceb7e44896d8e9a73c","39658203fb344f7f8c5a27c7c4d809ae","354beda37ddb48bdabe79c7ff33e8d8d","91e8336cc6f845d3a688162c72102509"]},"outputId":"e2e7c7b9-de9b-4c7d-8883-ea0ab119db84"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6399 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48090858c0f74d479bf4a05b162415da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4b3d5462d4947a5a292d72f2dd3f970"}},"metadata":{}}],"source":["tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UudQc2QLUYCA","executionInfo":{"status":"ok","timestamp":1712470985682,"user_tz":420,"elapsed":1189,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"colab":{"base_uri":"https://localhost:8080/","height":582},"outputId":"20de928d-a6f2-4210-ce55-bf7a6fbb4241"},"outputs":[{"output_type":"stream","name":"stdout","text":["7999\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","\n","def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n","    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n","    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n","    print(len(lengths))\n","\n","    # Plotting the histogram\n","    plt.figure(figsize=(10, 6))\n","    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n","    plt.xlabel('Length of input_ids')\n","    plt.ylabel('Frequency')\n","    plt.title('Distribution of Lengths of input_ids')\n","    plt.show()\n","\n","plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"]},{"cell_type":"code","source":["max_length = 256 # This was an appropriate max length for my dataset\n","\n","def generate_and_tokenize_prompt2(prompt):\n","    result = tokenizer(\n","        formatting_func(prompt),\n","        truncation=True,\n","        max_length=max_length,\n","        padding=\"max_length\",\n","    )\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","    return result"],"metadata":{"id":"QbQRo6-toCNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n","tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["75771b30f4954bf9b766379540fbd149","eac5221a6f994fed96d9efed2cd79b88","b11df70c3a864ce8941c36420e86c432","18c95817ae7448c894d0f37117b712c8","af3b176b6b63408b9cbf651aa68a5adb","084a56b0c5c74631b68bed7e10dc8050","0f6f228d1bfa431ebb3a12f972f695bc","bb182d4a8d2f4e9cb967bf63e4be2049","8b3d0c1b724348a5aa6f4417d9d7a9d5","a27144160e1e41baad095d4fea80f0cb","fcde0788c3894e4c898d242750e3aeca","deb64ec37bcc4b55b4def271283bc7ea","d350d87ecdc44df1b52097984cba71a0","6d2bd6ae218a4607804f41c2d0afc3e3","ded0c705d0df4e0f8cf374b8cd795629","77946e59137043b2b17a757775bb0b14","d01d42c0ec3e4f9690f30d0f4dea9f7f","6eb149cc7b994cd89f1e6c816bfddeb1","0d77195f2cb0458d8205fc72a2d14bb0","c696d24a92d94d3a92f1ceb37bb26666","eb213bd8dbb44a71981cdb429588c33b","46d34b0ffc9145af98fe5ebdee3d53eb"]},"id":"U3l4y9d5qiwQ","executionInfo":{"status":"ok","timestamp":1712470994359,"user_tz":420,"elapsed":3565,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"c5b40c6d-5188-4942-f899-17b631756e30"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6399 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75771b30f4954bf9b766379540fbd149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deb64ec37bcc4b55b4def271283bc7ea"}},"metadata":{}}]},{"cell_type":"markdown","source":["### How does the model performs?"],"metadata":{"id":"TO3RhQyxsuLn"}},{"cell_type":"code","source":["eval_prompt = \"\"\" Translate the following sentences from Hindi to English. The output should be in English and no other language.\n","### Romanized Hindi: vidhi\n","### English:\"\"\""],"metadata":{"id":"TKdxHeZFswch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Init an eval tokenizer that doesn't add padding or eos token\n","eval_tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id,\n","    add_bos_token=True,\n",")\n","\n","model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","model.eval()\n","with torch.no_grad():\n","    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U96FZjSpsrtj","executionInfo":{"status":"ok","timestamp":1712471029858,"user_tz":420,"elapsed":33858,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"667bcb1f-7292-4615-83ab-b0225a76fd76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" Translate the following sentences from Hindi to English. The output should be in English and no other language.\n","### Romanized Hindi: vidhi\n","### English: rule\n"]}]},{"cell_type":"code","source":["from peft import prepare_model_for_kbit_training\n","\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"],"metadata":{"id":"OHvHOTGKvuLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","        \"lm_head\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)"],"metadata":{"id":"2oBnAAZ-vzep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if torch.cuda.device_count() > 1: # If more than 1 GPU\n","    model.is_parallelizable = True\n","    model.model_parallel = True"],"metadata":{"id":"6_sQjHp_v25b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = accelerator.prepare_model(model)\n"],"metadata":{"id":"3NEY9zS-v4ga"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","from datetime import datetime\n","\n","project = \"journal-finetune\"\n","base_model_name = \"mistral\"\n","run_name = base_model_name + \"-\" + project\n","output_dir = \"./\" + run_name\n","\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=tokenized_train_dataset,\n","    eval_dataset=tokenized_val_dataset,\n","    args=transformers.TrainingArguments(\n","        output_dir=output_dir,\n","        warmup_steps=1,\n","        per_device_train_batch_size=2,\n","        gradient_accumulation_steps=1,\n","        gradient_checkpointing=True,\n","        max_steps=500,\n","        learning_rate=2.5e-5, # Want a small lr for finetuning\n","        bf16=True,\n","        optim=\"paged_adamw_8bit\",\n","        logging_steps=25,              # When to start reporting loss\n","        logging_dir=\"./logs\",        # Directory for storing logs\n","        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n","        save_steps=25,                # Save checkpoints every 50 steps\n","        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n","        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n","        do_eval=True,                # Perform evaluation at the end of training\n","        # report_to=\"wand÷b\",           # Comment this out if you don't want to use weights & baises\n","        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3pEt3i4Xv6P0","executionInfo":{"status":"ok","timestamp":1712402218239,"user_tz":420,"elapsed":6296229,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"e3c40539-688c-4d2f-ead6-6b31c8547576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [500/500 1:44:53, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>3.142000</td>\n","      <td>2.216603</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.967100</td>\n","      <td>1.892830</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.908900</td>\n","      <td>1.721756</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.530700</td>\n","      <td>1.627403</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>1.609900</td>\n","      <td>1.544060</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.428000</td>\n","      <td>1.481639</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>1.662200</td>\n","      <td>1.410243</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.537800</td>\n","      <td>1.363004</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>1.287900</td>\n","      <td>1.314901</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.317700</td>\n","      <td>1.287571</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>1.086000</td>\n","      <td>1.272584</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.383200</td>\n","      <td>1.239309</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>1.143600</td>\n","      <td>1.214134</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.199700</td>\n","      <td>1.186240</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>1.286800</td>\n","      <td>1.158032</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.056800</td>\n","      <td>1.141545</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>1.029300</td>\n","      <td>1.133387</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.053700</td>\n","      <td>1.121642</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>1.239100</td>\n","      <td>1.116646</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.100600</td>\n","      <td>1.114760</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=500, training_loss=1.4485468292236328, metrics={'train_runtime': 6295.6623, 'train_samples_per_second': 0.159, 'train_steps_per_second': 0.079, 'total_flos': 1.1052597116928e+16, 'train_loss': 1.4485468292236328, 'epoch': 0.16})"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","base_model_id = \"mistralai/Mistral-7B-v0.1\"\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,  # Mistral, same as before\n","    quantization_config=bnb_config,  # Same quantization config as before\n","    device_map=\"auto\",\n","    trust_remote_code=True,\n",")\n","\n","eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["87ffe6c2ac3c49f69bb170a9989fa221","1e7675f97eb14ae89cf87e4477f8f0e8","4ee1bbf875014003bf275628f1917da2","f9f90fc7519a4992b2d0f9f6bf405d48","fcfa0800b2994440a6698e0dfe3632ab","1502c78464b44161a62e9d76f46c7593","38448fe5088f4e06952753203fa4dbe6","cf8e01d02308433f9ae565b315202460","7e28c9d295b44eebb34f127f96f1a8a9","7a280b2158b54be281dcb698a7902898","3957082b0e8d46729a88c0a312338640"]},"id":"z-RzHF6JJP68","executionInfo":{"status":"ok","timestamp":1712471988650,"user_tz":420,"elapsed":107714,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"2348e2cd-0d70-4726-84f8-100745a0f56c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ffe6c2ac3c49f69bb170a9989fa221"}},"metadata":{}}]},{"cell_type":"code","source":["from peft import PeftModel\n","\n","ft_model = PeftModel.from_pretrained(base_model, \"/content/drive/MyDrive/Colab Notebooks/CSCI 564 NLP/mistral-journal-finetune/checkpoint-500\")"],"metadata":{"id":"iCo22xT6JXKo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_prompt = \"### Romanized Hindi: ack say adhik widget focus main hai\\n### English:\"\n","model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","ft_model.eval()\n","with torch.no_grad():\n","    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=50, repetition_penalty=1.15)[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPggjRrhJZzC","executionInfo":{"status":"ok","timestamp":1712473774326,"user_tz":420,"elapsed":15032,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"23dcbf50-96a1-4a1f-edf0-a44f6a919bbb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["### Romanized Hindi: ack say adhik widget focus main hai\n","### English: more than one focused widgets defocus publictext publictext publictext\n","### Chinese:  publictext public text public text public text\n","### French:  _ Focus public text\n","### Italian: _ Focus pubblico testo\n","### Russian:\n"]}]},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n","\n","# Assume test_data is a list of tuples: (source_sentence, reference_translation)\n","\n","sources = eval_dataset['hindi']\n","references = eval_dataset['english']"],"metadata":{"id":"VAuGLgusaAV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trans = []\n","refs = []\n","\n","ft_model.eval()\n","for i in range(len(sources)):\n","    eval_prompt = f\"### Romanized Hindi: {sources[i]}\\n### English:\"\n","    model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n","    with torch.no_grad():\n","      outputs = ft_model.generate(**model_input, max_new_tokens=50, repetition_penalty=1.15)[0]\n","      text = eval_tokenizer.decode(outputs, skip_special_tokens=True)\n","      t = text.split(\"\\n### English: \")\n","      t = t[1]. split(\"\\n\")[0]\n","      trans.append(t.split())\n","      refs.append(references[i].split())  # Note: reference must be a list of lists for corpus_bleu"],"metadata":{"id":"RRULhC7ljm0A","executionInfo":{"status":"error","timestamp":1712478829279,"user_tz":420,"elapsed":3513184,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"abb75a1b-63df-41f7-e149-7ef75b283771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-e124a5c71182>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m       \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n### English: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgeneration_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGenerationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGREEDY_SEARCH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;31m# 11. run greedy search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m             return self.greedy_search(\n\u001b[0m\u001b[1;32m   1545\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2403\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2404\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2405\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 )\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1043\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/bnb.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dora\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_adapter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlora_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_dora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlora_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlora_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["print(trans[7])\n","print(refs[7])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYNNnXcS2nkg","executionInfo":{"status":"ok","timestamp":1712479002540,"user_tz":420,"elapsed":12,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"outputId":"9d0f4d33-a7f3-4c4e-be5e-725f6a140aed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Move', '~', 'a', 'onto', 'the', 'unknown', 'card.']\n","['Move', '~', 'a', 'onto', 'the', 'unknown', 'card.']\n"]}]},{"cell_type":"code","source":["score = corpus_bleu(refs, trans, weights=[0.0, 0.25, 0.25, 0.0])\n","scores = []\n","\n","avg = 0\n","\n","for i in trans:\n","  # score = sentence_bleu(r, i, weights=[0.001,0.001,0,0])\n","  score = sentence_bleu(refs, i, weights=[0.25,0.001,0,0]) # unigram, bigram, trigram, quadrigram\n","  scores.append(score)\n","  avg += score\n","\n","avg = avg/len(trans)\n","print(scores)\n","print(\"Average BLEU score: \", avg)"],"metadata":{"id":"VtnXPfEBojRs","executionInfo":{"status":"ok","timestamp":1712478902886,"user_tz":420,"elapsed":7857,"user":{"displayName":"Sebastian Escalante","userId":"06485154265099791954"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e1f7349a-168c-45e3-c418-dac04ade968f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["[0.44496364554426016, 0.28430645296078766, 0.9027744206798209, 0.4140853306672728, 0.8221911415088685, 0, 0.37416833445639286, 1.0, 0.9029758914477024, 0.4772472098481303, 0.9029758914477024, 0.44496364554426016, 0.37416833445639286, 1.0, 0, 1.0, 0.45826074866259997, 0, 0.4924332214477753, 0.9295830465586772, 0.9133164869518604, 1.0, 0.45826074866259997, 0.9454695752285901, 0.37416833445639286, 0.9993070929904525, 0, 0.858006684437339, 0.8920792957788916, 1.0, 1.0, 1.0, 0, 0.39843102447353995, 0, 0.4924332214477753, 0.46571458717863623, 0.9611389588891094, 0.44496364554426016, 0.9638642340599155, 1.0, 1.0, 0.7582572934179451, 0.4140853306672728, 1.0, 0.4140853306672728, 0.27355837777461683, 0.4924332214477753, 0, 0.37416833445639286, 0.8795019012017843, 0, 1.0, 0.3916177268898787, 0.28430645296078766, 0.8873304756423315, 0.4140853306672728, 0.4140853306672728, 0.4140853306672728, 0.3104125402631453, 0, 0.44496364554426016, 0.8574121655914537, 0.4140853306672728, 0.9618054005930009, 1.0, 0.4140853306672728, 1.0, 0.44496364554426016, 0.45826074866259997, 1.0, 0.9295830465586772, 1.0, 1.0, 0.9029758914477024, 0.4140853306672728, 0, 0.8874112013453814, 0.9652880176340147, 0.4140853306672728, 1.0, 0.9539063031249821, 0.37416833445639286, 0.4140853306672728, 1.0, 0.9620200452131531, 1.0, 0, 1.0, 0.4924332214477753, 0.8788924881695311, 0.6600870674908543, 0.4924332214477753, 0.44496364554426016, 1.0, 0.250221446096888, 0, 0.9295830465586772, 1.0, 1.0, 0.4140853306672728, 1.0, 0.250221446096888, 0.9029758914477024, 1.0, 0.44496364554426016, 1.0, 0.37416833445639286, 0, 0.9504109385279544, 0.9998458612007783, 0.9993070929904525, 0.37416833445639286, 1.0, 0.4140853306672728, 0.37416833445639286, 0.8874112013453814, 0.9029758914477024, 0, 1.0, 0.9994405407677746, 0.9027161588338763, 0.9295830465586772, 0.4140853306672728, 0.34820287016725876, 0.9029758914477024, 0.4140853306672728, 0, 0.4140853306672728, 0, 0.9029758914477024, 0.42182859491929475, 0.44496364554426016, 0.28839824485053, 0.23907227712822515, 0.4140853306672728, 0.7583955526715697, 1.0, 0.9302276077885885, 0.23907227712822515, 0.4140853306672728, 0.23285729358931812, 0.4140853306672728, 1.0, 0.2674070693311289, 0.3916177268898787, 0.9029758914477024, 0.44496364554426016, 0.4140853306672728, 0.9620200452131531, 0.9994893048254297, 1.0, 0.44496364554426016, 0.4140853306672728, 1.0, 0.4924332214477753, 0, 0.37416833445639286, 1.0, 0.4333962577831672, 0.9242326114358529, 0.9545677297960456, 0.9752791729334953, 0, 0.4333962577831672, 0.9450862980130769, 0.37416833445639286, 0, 0.44496364554426016, 1.0, 0.44496364554426016, 0.8395441331814932, 1.0, 1.0, 0, 0.6945422146121077, 0.4140853306672728, 1.0, 0, 1.0, 0.9302276077885885, 0.37416833445639286, 0.9703107421112596, 0.44496364554426016, 0.37416833445639286, 0.34820287016725876, 1.0, 0.99959461708176, 0.4140853306672728, 1.0, 0, 1.0, 0.49807862735675906, 0.4924332214477753, 0.4140853306672728, 0.37416833445639286, 0.4924332214477753, 0.4140853306672728, 0.4140853306672728, 0.9994405407677746, 0, 0.9454695752285901, 0.4140853306672728, 0.44496364554426016, 0.4333962577831672, 0.4924332214477753, 0.9300842236221211, 1.0, 0.4140853306672728, 0.37416833445639286, 0.9993070929904525, 0.3104125402631453, 1.0, 0.8399731033921644, 1.0, 0.902350213123066, 1.0, 0.954689763207085, 0, 0.9029758914477024, 1.0, 1.0, 0.8395441331814932, 0, 0.3916177268898787, 0.8399731033921644, 1.0, 0, 0.9029758914477024, 0.9029758914477024, 0.9029758914477024, 1.0, 0.3146368111458337, 0.37416833445639286, 0.4140853306672728, 0, 0.8874112013453814, 0.37416833445639286, 0, 1.0, 1.0, 0.44496364554426016, 0.9996635843638134, 0.9027161588338763, 1.0, 0.9029758914477024, 1.0, 0.9378034425719354, 1.0, 0.4140853306672728, 0.20518769515542018, 0.44496364554426016, 0.4924332214477753, 0.9029758914477024, 0.37416833445639286, 0.9620200452131531, 0.34820287016725876, 0.8395441331814932, 0, 0.32403928293094847, 0.9176769848614071, 0.9287957464182391, 0.8395441331814932, 0.4140853306672728, 0.9618054005930009, 0.9659573362432216, 1.0, 0.4140853306672728, 0.44496364554426016, 1.0, 0.9993070929904525, 0, 0.4140853306672728, 1.0, 0.2975651240246891, 1.0, 1.0, 0, 0.5380563677473571, 1.0, 0.9029758914477024, 0.9183132905774087, 0, 0.4140853306672728, 0, 0.8795019012017843, 0.8399731033921644, 0.45826074866259997, 0, 0.9285121525454881, 0.960472978967346, 0.37416833445639286, 0.44496364554426016, 0, 1.0, 1.0, 0.9668428396251231, 1.0, 0, 1.0, 0.44496364554426016, 0, 0, 0.4924332214477753, 0.44496364554426016, 0.9029758914477024, 0.9029758914477024, 0.729801644523481, 0.99959461708176, 0, 0.9989019909648782, 1.0, 0.34820287016725876, 0.4140853306672728, 0.28430645296078766, 0.4924332214477753, 0, 1.0, 0.37416833445639286, 0.9029758914477024, 0.6304487448354924, 0, 0.99959461708176, 0.9302276077885885, 0.4653749325456494, 0.9029758914477024, 0.26633431061280766, 0.9454695752285901, 0, 0.9444314410925563, 1.0, 0.9444314410925563, 0.9295830465586772, 1.0, 1.0, 0, 0.37416833445639286, 0.37416833445639286, 0.4333962577831672, 0.37416833445639286, 0.45826074866259997, 0.335204082187508, 0.4020700416473343, 1.0, 0.9300842236221211, 0.4140853306672728, 0.9302276077885885, 1.0, 0.9444314410925563, 0.44496364554426016, 1.0, 0.4140853306672728, 0.4140853306672728, 0.9994893048254297, 0.8674206642221671, 1.0, 0.4140853306672728, 0.4140853306672728, 0.4924332214477753, 0.8399731033921644, 0.9029758914477024, 0.9993070929904525, 0.4924332214477753, 0.44496364554426016, 1.0, 0.45826074866259997, 0.44496364554426016, 0.9029758914477024, 0.44496364554426016, 0.34820287016725876, 0.4333962577831672, 0.7583955526715697, 0.4140853306672728, 0.44496364554426016, 0.4140853306672728, 0.9300842236221211, 0.9029758914477024, 0.8221911415088685, 0.9994893048254297, 0.23907227712822515, 1.0, 0, 0.9029758914477024, 1.0, 0.4140853306672728, 1.0, 0.4140853306672728, 0.37416833445639286, 1.0, 1.0, 0.4140853306672728, 0.4653749325456494, 0.49807862735675906, 0, 0.45826074866259997, 1.0, 0.9126836435561162, 0.9242326114358529, 0.9287957464182391, 0.4140853306672728, 0.4924332214477753, 0.45826074866259997, 1.0, 0.37416833445639286, 0, 1.0, 1.0, 0.1781084881048941, 0.9450862980130769, 1.0, 0.9668428396251231, 0.2425130502602737, 0.99959461708176, 0.9545677297960456, 0.9029758914477024, 0.37416833445639286, 1.0, 0.6304487448354924, 0.4140853306672728, 0.4140853306672728, 0.4140853306672728, 1.0, 0, 0.9615287462182229, 1.0, 1.0, 0.8192082735626914]\n","Average BLEU score:  0.6308597352391984\n"]}]},{"cell_type":"code","source":["peft_trainer.save_model('/content/drive/My Drive/CSCI544ProjOutput/saved_model')\n","tokenizer.save_pretrained('/content/drive/My Drive/CSCI544ProjOutput/saved_tokenizer')"],"metadata":{"id":"oT4iBay-xkhb"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"05755a531ebd4bf992711adc750d975e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a53e873b2b05404f959153fba082147a","IPY_MODEL_7bb4c80823fe4ab285f29674f0cd5e3b","IPY_MODEL_752f8bbe0eab45f0a86efa1ded41ed10"],"layout":"IPY_MODEL_8bd8e370cacd4297900e0f159159495a"}},"a53e873b2b05404f959153fba082147a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f25a63b6258496ea104c605fdd28aeb","placeholder":"​","style":"IPY_MODEL_c498d0c9139d4d2fa14dd577e1e9566d","value":"Generating train split: "}},"7bb4c80823fe4ab285f29674f0cd5e3b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c835da94c984ffa9676d3d038092a1e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_308962cecd0b4e64b4a81aa7a16de987","value":1}},"752f8bbe0eab45f0a86efa1ded41ed10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b525f2807234cc292c4034837872e48","placeholder":"​","style":"IPY_MODEL_7b31daa140484ba2a453c6d6091f3ec4","value":" 7999/0 [00:00&lt;00:00, 107186.86 examples/s]"}},"8bd8e370cacd4297900e0f159159495a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f25a63b6258496ea104c605fdd28aeb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c498d0c9139d4d2fa14dd577e1e9566d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c835da94c984ffa9676d3d038092a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"308962cecd0b4e64b4a81aa7a16de987":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b525f2807234cc292c4034837872e48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b31daa140484ba2a453c6d6091f3ec4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48090858c0f74d479bf4a05b162415da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fac0b02292284cbba2c7ee17e41c6d35","IPY_MODEL_1eb3feb1713549af83b9a079a1c4e56f","IPY_MODEL_82ca17377d6745e29bab9b8926ec278e"],"layout":"IPY_MODEL_2428ff9f56154c1d8d7077a8eb6d3713"}},"fac0b02292284cbba2c7ee17e41c6d35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36a5c7b4236a4969bbc4ce1d8be5f6ee","placeholder":"​","style":"IPY_MODEL_2088af3dc5d9450c9e6f2e6df178e7f0","value":"Map: 100%"}},"1eb3feb1713549af83b9a079a1c4e56f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3db84c5d1904ea0a41b1e48bc6b2306","max":6399,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2d3a41285d64ee5ab3df211ee2547c0","value":6399}},"82ca17377d6745e29bab9b8926ec278e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_646898f367fc460d80ab3b7b28cd5c30","placeholder":"​","style":"IPY_MODEL_bba3ca044f2448179e7105d36e225af2","value":" 6399/6399 [00:01&lt;00:00, 3735.26 examples/s]"}},"2428ff9f56154c1d8d7077a8eb6d3713":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36a5c7b4236a4969bbc4ce1d8be5f6ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2088af3dc5d9450c9e6f2e6df178e7f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3db84c5d1904ea0a41b1e48bc6b2306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d3a41285d64ee5ab3df211ee2547c0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"646898f367fc460d80ab3b7b28cd5c30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bba3ca044f2448179e7105d36e225af2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4b3d5462d4947a5a292d72f2dd3f970":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acce87a4dbcb4fcb94f0efa288586c58","IPY_MODEL_65ed925623434a6caea597864fc141df","IPY_MODEL_106e3a869c2a47d4957787d84434046e"],"layout":"IPY_MODEL_51f8fbc893604fc893c10d696dbae8e2"}},"acce87a4dbcb4fcb94f0efa288586c58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32df641bd8034ef5a4ac5a9fa0923e78","placeholder":"​","style":"IPY_MODEL_59d12f4991424b6b9875d55b5542f2c9","value":"Map: 100%"}},"65ed925623434a6caea597864fc141df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59a7f8e2b1a347ceb7e44896d8e9a73c","max":1600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_39658203fb344f7f8c5a27c7c4d809ae","value":1600}},"106e3a869c2a47d4957787d84434046e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_354beda37ddb48bdabe79c7ff33e8d8d","placeholder":"​","style":"IPY_MODEL_91e8336cc6f845d3a688162c72102509","value":" 1600/1600 [00:00&lt;00:00, 3872.44 examples/s]"}},"51f8fbc893604fc893c10d696dbae8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32df641bd8034ef5a4ac5a9fa0923e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59d12f4991424b6b9875d55b5542f2c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59a7f8e2b1a347ceb7e44896d8e9a73c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39658203fb344f7f8c5a27c7c4d809ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"354beda37ddb48bdabe79c7ff33e8d8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91e8336cc6f845d3a688162c72102509":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75771b30f4954bf9b766379540fbd149":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eac5221a6f994fed96d9efed2cd79b88","IPY_MODEL_b11df70c3a864ce8941c36420e86c432","IPY_MODEL_18c95817ae7448c894d0f37117b712c8"],"layout":"IPY_MODEL_af3b176b6b63408b9cbf651aa68a5adb"}},"eac5221a6f994fed96d9efed2cd79b88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_084a56b0c5c74631b68bed7e10dc8050","placeholder":"​","style":"IPY_MODEL_0f6f228d1bfa431ebb3a12f972f695bc","value":"Map: 100%"}},"b11df70c3a864ce8941c36420e86c432":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb182d4a8d2f4e9cb967bf63e4be2049","max":6399,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b3d0c1b724348a5aa6f4417d9d7a9d5","value":6399}},"18c95817ae7448c894d0f37117b712c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a27144160e1e41baad095d4fea80f0cb","placeholder":"​","style":"IPY_MODEL_fcde0788c3894e4c898d242750e3aeca","value":" 6399/6399 [00:02&lt;00:00, 2451.82 examples/s]"}},"af3b176b6b63408b9cbf651aa68a5adb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"084a56b0c5c74631b68bed7e10dc8050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f6f228d1bfa431ebb3a12f972f695bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb182d4a8d2f4e9cb967bf63e4be2049":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3d0c1b724348a5aa6f4417d9d7a9d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a27144160e1e41baad095d4fea80f0cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcde0788c3894e4c898d242750e3aeca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"deb64ec37bcc4b55b4def271283bc7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d350d87ecdc44df1b52097984cba71a0","IPY_MODEL_6d2bd6ae218a4607804f41c2d0afc3e3","IPY_MODEL_ded0c705d0df4e0f8cf374b8cd795629"],"layout":"IPY_MODEL_77946e59137043b2b17a757775bb0b14"}},"d350d87ecdc44df1b52097984cba71a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d01d42c0ec3e4f9690f30d0f4dea9f7f","placeholder":"​","style":"IPY_MODEL_6eb149cc7b994cd89f1e6c816bfddeb1","value":"Map: 100%"}},"6d2bd6ae218a4607804f41c2d0afc3e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d77195f2cb0458d8205fc72a2d14bb0","max":1600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c696d24a92d94d3a92f1ceb37bb26666","value":1600}},"ded0c705d0df4e0f8cf374b8cd795629":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb213bd8dbb44a71981cdb429588c33b","placeholder":"​","style":"IPY_MODEL_46d34b0ffc9145af98fe5ebdee3d53eb","value":" 1600/1600 [00:00&lt;00:00, 2221.41 examples/s]"}},"77946e59137043b2b17a757775bb0b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d01d42c0ec3e4f9690f30d0f4dea9f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6eb149cc7b994cd89f1e6c816bfddeb1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d77195f2cb0458d8205fc72a2d14bb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c696d24a92d94d3a92f1ceb37bb26666":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb213bd8dbb44a71981cdb429588c33b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46d34b0ffc9145af98fe5ebdee3d53eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87ffe6c2ac3c49f69bb170a9989fa221":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e7675f97eb14ae89cf87e4477f8f0e8","IPY_MODEL_4ee1bbf875014003bf275628f1917da2","IPY_MODEL_f9f90fc7519a4992b2d0f9f6bf405d48"],"layout":"IPY_MODEL_fcfa0800b2994440a6698e0dfe3632ab"}},"1e7675f97eb14ae89cf87e4477f8f0e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1502c78464b44161a62e9d76f46c7593","placeholder":"​","style":"IPY_MODEL_38448fe5088f4e06952753203fa4dbe6","value":"Loading checkpoint shards: 100%"}},"4ee1bbf875014003bf275628f1917da2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf8e01d02308433f9ae565b315202460","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7e28c9d295b44eebb34f127f96f1a8a9","value":2}},"f9f90fc7519a4992b2d0f9f6bf405d48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a280b2158b54be281dcb698a7902898","placeholder":"​","style":"IPY_MODEL_3957082b0e8d46729a88c0a312338640","value":" 2/2 [01:20&lt;00:00, 37.29s/it]"}},"fcfa0800b2994440a6698e0dfe3632ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1502c78464b44161a62e9d76f46c7593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38448fe5088f4e06952753203fa4dbe6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf8e01d02308433f9ae565b315202460":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e28c9d295b44eebb34f127f96f1a8a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a280b2158b54be281dcb698a7902898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3957082b0e8d46729a88c0a312338640":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}